facet_wrap(~File, ncol = 2, scales = "free_x")
sentiment <- filter(words.list,President=='Andrew Jackson'&Term=='2') %>%
inner_join(get_sentiments("bing")) %>%
count(File, index = sent.id, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(sentiment, aes(index, sentiment, fill = File)) +
geom_col(show.legend = FALSE) +
facet_wrap(~File, ncol = 2, scales = "free_x")
View(speech.list)
words.list$File <- paste(words.list$File,words.list$Term)
words.list <- sentence.list %>%
unnest_tokens(word, sentences)
data(stop_words)
words.list <- words.list %>%
anti_join(stop_words)
words.list
words.list$File <- paste(words.list$File,words.list$Term,sep='')
select_president <- c('John F. Kennedy', 'Barack Obama','George Bush', 'Donald J. Trump')
?%in%
'Barack Obama'%in%select_president
sentiment <- filter(words.list,File%in%select_president) %>%
inner_join(get_sentiments("bing")) %>%
count(File, index = sent.id, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
sentiment <- filter(words.list,President%in%select_president) %>%
inner_join(get_sentiments("bing")) %>%
count(File, index = sent.id, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(sentiment, aes(index, sentiment, fill = File)) +
geom_col(show.legend = FALSE) +
facet_wrap(~File, ncol = 2, scales = "free_x")
dtm_demo <- DocumentTermMatrix(corpus_demo,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
tf_idf_demo=tidy(dtm)
tf_idf_demo=tidy(dtm_demo)
tf_idf_demo
dtm_repub <- DocumentTermMatrix(corpus_repub,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
tf_idf_repub=tidy(repub)
tf_idf_repub=tidy(dtm_repub)
tf_idf_repub
?arrange
arrange(tf_idf_demo,desc(count))
arrange(tf_idf_repub,desc(count))
tf_idf_repub
arrange(tf_idf_repub,desc(count))
?mutate
tf_idf_demo
setwd("~/Google Drive/Han's Stuff/MyKlovr/Inject_Scraped")
setwd("~/GitHub/fall2017-project1-budingtanke")
setwd("~/Google Drive/Han's Stuff/MyKlovr/Inject_Scraped")
speeches <- read.csv("../data/InaugurationInfo.csv")
getwd()
speeches <- read.csv("../data/InaugurationInfo.csv")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Google Drive/Han's Stuff/MyKlovr/Inject_Scraped")
library(stringr)
# change colnames
colnames(CollegeSimplyAdmisData)
CollegeSimplyAdmisData <- read.csv('Inject_Scraped/CollegeSimplyAdmisData.csv',header = T)[,-1]
getwd()
setwd("~/Google Drive/Han's Stuff/MyKlovr")
setwd("~/Google Drive/Han's Stuff/MyKlovr")
#setwd("~/Google Drive/Han's Stuff/MyKlovr")
combined <- read.csv("Inject_Scraped/combined 09-11.csv",header = T)
knitr::opts_knit$set(root.dir = "~/Google Drive/Han's Stuff/MyKlovr")
setwd("~/Google Drive/Han's Stuff/MyKlovr")
setwd("~/Google Drive/Han's Stuff/MyKlovr")
#setwd("~/Google Drive/Han's Stuff/MyKlovr")
combined <- read.csv("Inject_Scraped/combined 09-11.csv",header = T)
getwd()
combined <- read.csv("Inject_Scraped/combined 09-11.csv",header = T)
setwd("~/Google Drive/Han's Stuff/MyKlovr")
combined <- read.csv("Inject_Scraped/combined 09-11.csv",header = T)
setwd("~/Google Drive/Han's Stuff/MyKlovr")
combined <- read.csv("Inject_Scraped/combined 09-11.csv",header = T)
setwd("~/Google Drive/Han's Stuff/MyKlovr/Inject_Scraped")
combined <- read.csv("combined 09-11.csv",header = T)
combined <- read.csv("combined 09-11.csv",header = T)
combined <- combined[,-c(1,2)]
dim(combined)
dim(combined)
combined$state <- as.character(combined$state)
head(combined[,c('ARCO_name','SAT_total_p1','ave_fresh_GPA')],20)
sum(is.na(combined$state))
CollegeSimplyAdmisData <- read.csv('Inject_Scraped/CollegeSimplyAdmisData.csv',header = T)[,-1]
CollegeSimplyAdmisData <- read.csv('CollegeSimplyAdmisData.csv',header = T)[,-1]
# change colnames
colnames(CollegeSimplyAdmisData)
colnames(CollegeSimplyAdmisData) <- c('school','State','SAT_total_p3','SAT_total_p1',
'ACT_total_p3','ACTrange_comp_2','ave_fresh_GPA','Acceptance.Rate')
CollegeSimplyAdmisData$State <- state.abb[match(CollegeSimplyAdmisData$State,state.name)]
CollegeSimplyAdmisData$School <- as.character(CollegeSimplyAdmisData$school)
# remove punctuations from ARCO_name
combined$ARCO_name_new <- sapply(combined$ARCO_name,function(x){return(rm_white(gsub("[-,.]", " ", x)))})
sub <- combined[,c('ARCO_name','ARCO_name_new')]
CollegeSimplyAdmisData$School[c(3,7,11,44,61,82,87,95,107,109,111,128,129,130,136)] <- c('The University of Chicago','Columbia University','Franklin W. Olin College of Engineering','University of Virginia','Georgia Institute of Technology','The George Washington University','Binghamton University The State University of New York','The University of Tulsa','North Carolina State University Raleigh','University of Pittsburgh','University of Washington Seattle','Nebraska Methodist College','Rutgers the State University of New Jersey New Brunswick','SUNY New Paltz','Purdue University West Lafayette')
# join two dataframes
combined <- left_join(combined,CollegeSimplyAdmisData,by=c('ARCO_name_new'='school'))
# remove unmatched rows
combined$State <- ifelse(is.na(combined$State),combined$state,combined$State)
combined <- combined[combined$state==combined$State,]
combined$State <- NULL
dim(combined)
# use scraped data, and use combined data unless scraped data is NA
#new$a.x <- ifelse(is.na(new$a.x)&(!is.na(new$a.y)),new$a.y,new$a.x)
combined$SAT_total_p1 <- ifelse((!is.na(combined$SAT_total_p1.x))&
(is.na(combined$SAT_total_p1.y)),combined$SAT_total_p1.x,combined$SAT_total_p1.y)
combined$SAT_total_p1.x <- NULL
combined$SAT_total_p1.y <- NULL
combined$ACTrange_comp_2 <- ifelse((!is.na(combined$ACTrange_comp_2.x))&
(is.na(combined$ACTrange_comp_2.y)),combined$ACTrange_comp_2.x,
combined$ACTrange_comp_2.y)
combined$ACTrange_comp_2.x <- NULL
combined$ACTrange_comp_2.y <- NULL
combined$ave_fresh_GPA <- ifelse((!is.na(combined$ave_fresh_GPA.x))&
(is.na(combined$ave_fresh_GPA.y)),combined$ave_fresh_GPA.x,
combined$ave_fresh_GPA.y)
combined$ave_fresh_GPA.x <- NULL
combined$ave_fresh_GPA.y <- NULL
dim(combined)
head(combined[,c('ARCO_name','SAT_total_p1','SAT_total_p3','ACT_total_p3','ACTrange_comp_2','ave_fresh_GPA')],20)
write.csv(combined,'combined 09-18.csv')
head(combined[,c('ARCO_name','SAT_total_p1','SAT_total_p3','ACT_total_p3','ACTrange_comp_2','ave_fresh_GPA')],20)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Google Drive/Han's Stuff/MyKlovr/Inject_Sraped")
library(janeaustenr)
austen_books()
View(tdm.tidy_demo)
View(tf_idf_demo)
View(tf_idf_demo)
dtm_demo <- DocumentTermMatrix(corpus_demo,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
tf_idf_demo <- tidy(dtm_demo)
View(tf_idf_demo)
View(tdm.tidy_repub)
View(tdm.tidy_demo)
View(tdm.tidy_demo)
View(tdm.tidy_demo)
View(tf_idf_demo)
arrange(tf_idf_demo,desc(count))
?weightTfIdf()
ggplot(sentence.list, aes(factor(Party), word.count)) +
geom_violin(aes(fill = Party))+
xlab('Party')
par(mfrow=c(1,2))
ggplot(filter(speech.list,Party=='Democratic'),aes(x=President,y=Words))+
geom_bar(stat = "identity",aes(fill = factor(Party)))+
#scale_x_discrete(limits = speech.list$President)+
#coord_flip()
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(filter(speech.list,Party=='Republican'),aes(x=President,y=Words))+
geom_bar(stat = "identity",aes(fill = factor(Party)))+
#scale_x_discrete(limits = speech.list$President)+
#coord_flip()
theme(axis.text.x=element_text(angle=45, hjust=1))
par(mfrow=c(1,2))
ggplot(filter(speech.list,Party=='Democratic'),aes(x=President,y=Words))+
geom_bar(stat = "identity",aes(fill = factor(Party)))+
#scale_x_discrete(limits = speech.list$President)+
#coord_flip()
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(filter(speech.list,Party=='Republican'),aes(x=President,y=Words))+
geom_bar(stat = "identity",aes(fill = factor(Party)))+
#scale_x_discrete(limits = speech.list$President)+
#coord_flip()
theme(axis.text.x=element_text(angle=45, hjust=1))
?count
?d*ply
library(plyr)
?d*ply
d*ply(words.list,.(File),function(x){return(sum(x[,'word']=='government'))})
daply(words.list,.(File),function(x){return(sum(x[,'word']=='government'))})
ddply(words.list,.(File),function(x){return(sum(x[,'word']=='government'))})
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
arrange(V1)
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
colname()[,2:3] <- c('data','count')
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
?as.Date
words.list$links <- as.Date(words.list$links, format="%m %c, %Y")
words.list <- sentence.list %>%
unnest_tokens(word, sentences)
data(stop_words)
words.list <- words.list %>%
anti_join(stop_words)
words.list
words.list$File <- paste(words.list$File,words.list$Term,sep='')
as.Date('March 4, 1829',format="%m %d, %Y")
as.Date('March 4, 1829',format="%B %d, %Y")
words.list$links <- as.Date(words.list$links, format="%B %d, %Y")
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
arrange(links)
dply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
words.list <- sentence.list %>%
unnest_tokens(word, sentences)
data(stop_words)
words.list <- words.list %>%
anti_join(stop_words)
words.list$File <- paste(words.list$File,words.list$Term,sep='')
words.list$links <- as.Date(words.list$links, format="%B %d, %Y")
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
arrange(links)
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
arrange(V1)
words.list <- sentence.list %>%
unnest_tokens(word, sentences)
data(stop_words)
words.list <- words.list %>%
anti_join(stop_words)
words.list
words.list$links <- as.Date(words.list$links, format="%B %d, %Y")
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
arrange(V1)
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
words.list <- sentence.list %>%
unnest_tokens(word, sentences)
words.list <- words.list %>%
anti_join(stop_words)
words.list$File <- paste(words.list$File,words.list$Term,sep='')
words.list$links <- as.Date(words.list$links, format="%B %d, %Y")
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
words.list <- sentence.list %>%
unnest_tokens(word, sentences)
words.list <- words.list %>%
anti_join(stop_words)
words.list$File <- paste(words.list$File,words.list$Term,sep='')
as.Date(words.list$links, format="%B %d, %Y")
words.list$links <- as.character(as.Date(words.list$links, format="%B %d, %Y"))
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))})
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='government')))}) %>%
arrange(V1)
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='world')))}) %>%
arrange(V1)
ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']=='people')))}) %>%
arrange(V1)
word_trend <- function(word){
return(ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word)))}) %>%
arrange(V1))
}
word_trend('peace')
ggplot(word_trend('peace'),aes(V1,V2))
ggplot(word_trend('peace'),aes(V1,V2))+
geom_point(V1,V2)
ggplot(word_trend('peace'),aes(V1,V2))+
geom_point(V1,as.integer(V2))
word_trend('peace')
temp <- word_trend('peace')
ggplot(temp,aes(V1,V2))+
geom_point(V1,V2)
ggplot(temp,aes(V1,V2))+
geom_point()
ggplot(temp,aes(V1,V2))+
geom_line()
ggplot(temp,aes(V1,V2))+
geom_line(V1,V2)
ggplot(temp,aes('V1','V2'))+
geom_line()
ggplot(temp,aes(V1,V2))+
geom_line()
word_trend <- function(word){
temp <- dply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word)))}) %>%
arrange(V1)
temp$V2 <- as.character(temp$V2)
return(temp)
}
temp <- word_trend('peace')
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word)))}) %>%
arrange(V1)
temp$V2 <- as.character(temp$V2)
return(temp)
}
temp <- word_trend('peace')
ggplot(temp,aes(V1,V2))+
geom_line()
temp
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word)))}) %>%
arrange(V1)
temp$V2 <- as.integer(temp$V2)
return(temp)
}
temp <- word_trend('peace')
temp
ggplot(temp,aes(V1,V2))+
geom_line()
ggplot(temp,aes(File,V2))+
geom_line()
ggplot(temp,aes(File,V2))+
geom_jitter()
ggplot(temp,aes(File,V2))+
geom_point()+geom(line)
ggplot(temp,aes(File,V2))+
geom_point()+geom_line()
ggplot(temp,aes(File,V2))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(temp,aes(File,V2,group=1))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word),unique(x[,'Party'])))}) %>%
arrange(V1)
temp$V2 <- as.integer(temp$V2)
return(temp)
}
temp <- word_trend('peace')
temp
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word),unique(as.character(x[,'Party']))))}) %>%
arrange(V1)
temp$V2 <- as.integer(temp$V2)
return(temp)
}
temp <- word_trend('peace')
temp
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word),unique(as.character(x[,'Party']))))}) %>%
arrange(V1)
colnames(x) <- c('File','Date','Count','Party'))
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word),unique(as.character(x[,'Party']))))}) %>%
arrange(V1)
colnames(x) <- c('File','Date','Count','Party')
temp$V2 <- as.integer(temp$V2)
return(temp)
}
temp <- word_trend('peace')
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word),unique(as.character(x[,'Party']))))}) %>%
arrange(V1)
colnames(temp) <- c('File','Date','Count','Party')
temp$V2 <- as.integer(temp$V2)
return(temp)
}
temp <- word_trend('peace')
word_trend <- function(word){
temp <- ddply(words.list,.(File),function(x){
return(c(unique(x[,'links']),sum(x[,'word']==word),unique(as.character(x[,'Party']))))}) %>%
arrange(V1)
colnames(temp) <- c('File','Date','Count','Party')
temp$Count <- as.integer(temp$Count)
return(temp)
}
temp <- word_trend('peace')
temp
ggplot(temp,aes(File,V2,group=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(temp,aes(File,Count,group=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(temp,aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('freedom'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('america'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('tax'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
#head(sort(tdm.overall_demo$`sum(count)`,decreasing = T),100)
ggplot(subset(tdm.overall_demo,`sum(count)`>100),aes(term,`sum(count)`))+
geom_bar(stat='identity')+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(subset(tdm.overall_repub,`sum(count)`>100),aes(term,`sum(count)`))+
geom_bar(stat='identity')+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(subset(rbind(tdm.overall_demo,tdm.overall_repub),`sum(count)`>100),aes(term,`sum(count)`))+
geom_bar(stat='identity')+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('people'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('government'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('world'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('country'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('peace'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('nation'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('women'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('woman'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('must'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('states'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('america'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
ggplot(word_trend('freedom'),aes(File,Count,group=Party,color=Party))+
geom_point()+geom_line()+
theme(axis.text.x=element_text(angle=45, hjust=1))
range(combined$tuition_instate)
min(combined$tuition_instate,na.rm = T)
max(combined$tuition_instate,na.rm = T)
max(combined$tuition_outstate,na.rm = T)
tail(sort(combined$tuition_instate))
tail(sort(combined$tuition_outstate))
head(sort(combined$tuition_instate))
head(sort(combined$tuition_outstate))
head(sort(combined$total_under_3))
tail(sort(combined$total_under_3))
tail(sort(combined$total_grad_3))
knitr::opts_knit$set(root.dir = "~/GitHub/fall2017-project1-budingtanke")
packages.used=c("rvest", "qdap",  "tidytext","plyr",
"sentimentr", "gplots", "dplyr","tidyr",
"tm","topicmodels","ggplot2","wordcloud")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
lapply(packages.used, require, character.only = TRUE)
source("../lib/plotstacked.R")
source("../lib/plotstacked.R")
getwd()
setwd("~/GitHub/fall2017-project1-budingtanke")
source("../lib/plotstacked.R")
setwd("~/GitHub/fall2017-project1-budingtanke")
source("../lib/plotstacked.R")
getwd()
packages.used=c("rvest", "qdap",  "tidytext","plyr",
"sentimentr", "gplots", "dplyr","tidyr",
"tm","topicmodels","ggplot2","wordcloud")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
lapply(packages.used, require, character.only = TRUE)
source("../lib/plotstacked.R")
source("../lib/plotstacked.R")
speeches <- read.csv("../data/InaugurationInfo.csv")
setwd("~/")
source("../lib/plotstacked.R")
setwd("~/GitHub/fall2017-project1-budingtanke/doc")
source("../lib/plotstacked.R")
source("../lib/plotstacked.R")
source("../lib/plotstacked.R")
getwd()
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
